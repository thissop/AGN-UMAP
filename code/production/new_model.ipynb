{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, PReLU, Input, Reshape, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def build_encoder(input_shape, latent_dim):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional Layers\n",
    "    x = Conv1D(filters=128, kernel_size=5, padding='valid', name='conv1')(input_layer)\n",
    "    x = PReLU(name='prelu1')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool1')(x)\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=11, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(name='prelu2')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool2')(x)\n",
    "\n",
    "    x = Conv1D(filters=512, kernel_size=21, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(name='prelu3')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool3')(x)\n",
    "\n",
    "    # Flatten the output from Conv layers\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    x = Dense(256, name='dense1')(x)\n",
    "    x = PReLU(name='prelu4')(x)\n",
    "    x = Dense(128, name='dense2')(x)\n",
    "    x = PReLU(name='prelu5')(x)\n",
    "    x = Dense(64, name='dense3')(x)\n",
    "    x = PReLU(name='prelu6')(x)\n",
    "\n",
    "    # Latent Space\n",
    "    latent_space = Dense(latent_dim, name='latent_space')(x)\n",
    "\n",
    "    return Model(input_layer, latent_space, name='encoder')\n",
    "\n",
    "class ResampleLayer(Layer):\n",
    "    def __init__(self, rest_frame_length, output_dim, min_observed_wavelength, max_observed_wavelength, **kwargs):\n",
    "        super(ResampleLayer, self).__init__(**kwargs)\n",
    "        self.rest_frame_length = rest_frame_length\n",
    "        self.output_dim = output_dim\n",
    "        self.min_observed_wavelength = min_observed_wavelength\n",
    "        self.max_observed_wavelength = max_observed_wavelength\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ResampleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, z = inputs\n",
    "        min_rest_wavelength = self.min_observed_wavelength / 2.2\n",
    "        max_rest_wavelength = self.max_observed_wavelength / 1.5\n",
    "        rest_frame_wavelength = tf.linspace(min_rest_wavelength, max_rest_wavelength, self.rest_frame_length)\n",
    "        rest_frame_wavelength = tf.cast(rest_frame_wavelength, dtype=tf.float32)\n",
    "\n",
    "        z = tf.cast(z, tf.float32)\n",
    "        div = 1 + z\n",
    "\n",
    "        min_observed_wavelength_div = tf.cast(self.min_observed_wavelength / div, dtype=tf.float32)\n",
    "        max_observed_wavelength_div = tf.cast(self.max_observed_wavelength / div, dtype=tf.float32)\n",
    "\n",
    "        start_index = tf.argmin(tf.abs(rest_frame_wavelength - min_observed_wavelength_div), axis=0)\n",
    "        stop_index = tf.argmin(tf.abs(rest_frame_wavelength - max_observed_wavelength_div), axis=0)\n",
    "\n",
    "        start_index = tf.cast(start_index, tf.int32)\n",
    "        stop_index = tf.cast(stop_index, tf.int32)\n",
    "\n",
    "        batch_size = tf.shape(x)[0]\n",
    "\n",
    "        sections = []\n",
    "        for i in range(batch_size):\n",
    "            section = tf.slice(x[i], [start_index[i], 0], [stop_index[i] - start_index[i], -1])\n",
    "            sections.append(section)\n",
    "        sections = tf.stack(sections)\n",
    "\n",
    "        interpolated = tf.image.resize(sections, [self.output_dim, 1])\n",
    "\n",
    "        return tf.reshape(interpolated, [-1, self.output_dim, 1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim, 1)\n",
    "\n",
    "def build_decoder(latent_dim, output_dim, z_min, z_max, min_observed_wavelength, max_observed_wavelength):\n",
    "    latent_input = Input(shape=(latent_dim,))\n",
    "    redshift_input = Input(shape=(1,))\n",
    "\n",
    "    # Calculate rest frame wavelength range\n",
    "    min_rest_wavelength = min_observed_wavelength / z_max\n",
    "    max_rest_wavelength = max_observed_wavelength / z_min\n",
    "    rest_frame_range = max_rest_wavelength - min_rest_wavelength\n",
    "\n",
    "    # Calculate observed resolution\n",
    "    observed_resolution = (max_observed_wavelength - min_observed_wavelength) / output_dim\n",
    "\n",
    "    # Calculate rest frame length with twice the resolution\n",
    "    rest_frame_length = int((rest_frame_range / observed_resolution) * 2)\n",
    "    rest_frame_wavelength = tf.linspace(min_rest_wavelength, max_rest_wavelength, rest_frame_length)\n",
    "    rest_frame_wavelength = tf.cast(rest_frame_wavelength, dtype=tf.float32)\n",
    "    \n",
    "    # Fully Connected Layers to generate rest frame representation\n",
    "    x = Dense(64)(latent_input)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(rest_frame_length)(x)\n",
    "    x = Reshape((rest_frame_length, 1))(x)\n",
    "\n",
    "    # Interpolate and resample\n",
    "    def resample(args):\n",
    "        x, z = args\n",
    "\n",
    "        # Ensure z is of the correct type\n",
    "        z = tf.cast(z, tf.float32)\n",
    "\n",
    "        # Compute start and stop indices\n",
    "        min_observed_wavelength_div = tf.cast(min_observed_wavelength / (1 + z), dtype=tf.float32)\n",
    "        max_observed_wavelength_div = tf.cast(max_observed_wavelength / (1 + z), dtype=tf.float32)\n",
    "\n",
    "        start_index = tf.argmin(tf.abs(rest_frame_wavelength - min_observed_wavelength_div))\n",
    "        stop_index = tf.argmin(tf.abs(rest_frame_wavelength - max_observed_wavelength_div))\n",
    "\n",
    "        # Ensure start_index and stop_index are of the correct type\n",
    "        start_index = tf.cast(start_index, tf.int32)\n",
    "        stop_index = tf.cast(stop_index, tf.int32)\n",
    "\n",
    "        # Expand indices to match batch dimension\n",
    "        start_index = tf.expand_dims(start_index, axis=0)\n",
    "        stop_index = tf.expand_dims(stop_index, axis=0)\n",
    "\n",
    "        # Use tf.slice with dynamic shapes\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        batch_indices = tf.range(batch_size)\n",
    "        batch_indices = tf.expand_dims(batch_indices, axis=-1)\n",
    "\n",
    "        start_indices = tf.concat([batch_indices, start_index], axis=-1)\n",
    "        stop_indices = tf.concat([batch_indices, stop_index], axis=-1)\n",
    "\n",
    "        sections = []\n",
    "        for i in range(batch_size):\n",
    "            section = tf.slice(x[i], [start_indices[i][0], 0], [stop_indices[i][1] - start_indices[i][1], -1])\n",
    "            sections.append(section)\n",
    "        sections = tf.stack(sections)\n",
    "\n",
    "        interpolated = tf.image.resize(sections, [output_dim, 1])\n",
    "\n",
    "        return tf.reshape(interpolated, [-1, output_dim, 1])\n",
    "\n",
    "    # Specify output_shape\n",
    "    output = ResampleLayer(rest_frame_length, output_dim, min_observed_wavelength, max_observed_wavelength)([x, redshift_input])\n",
    "\n",
    "    return Model([latent_input, redshift_input], output, name='decoder')\n",
    "\n",
    "def build_autoencoder(input_shape, latent_dim, z_min, z_max, min_observed_wavelength, max_observed_wavelength):\n",
    "    spectra_input = Input(shape=input_shape, name='spectra_input')\n",
    "    redshift_input = Input(shape=(1,), name='redshift_input')\n",
    "\n",
    "    encoder = build_encoder(input_shape, latent_dim)\n",
    "    latent_space = encoder(spectra_input)\n",
    "    \n",
    "    decoder = build_decoder(latent_dim, input_shape[0], z_min, z_max, min_observed_wavelength, max_observed_wavelength)\n",
    "    reconstructed_output = decoder([latent_space, redshift_input])\n",
    "\n",
    "    return Model(inputs=[spectra_input, redshift_input], outputs=reconstructed_output, name='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3550.0 10400.0\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/tkiker/Documents/GitHub/AGN-UMAP/data/sdss_spectra'\n",
    "\n",
    "file_names = []\n",
    "spectra = []\n",
    "zs = []\n",
    "\n",
    "x = np.linspace(3550, 10400, 4500)\n",
    "\n",
    "for file_name in os.listdir(data_dir)[0:64]:\n",
    "    hdul = fits.open(os.path.join(data_dir, file_name))\n",
    "    \n",
    "    data = hdul[1].data\n",
    "\n",
    "    wavelength = 10**data[\"loglam\"]\n",
    "    flux = data[\"flux\"]\n",
    "\n",
    "    flux = gaussian_filter1d(flux, sigma=3)\n",
    "    flux = np.interp(x, wavelength, flux)\n",
    "\n",
    "    z = hdul[2].data['z'][0]\n",
    "\n",
    "    rest_wavelength = x/(1+z)\n",
    "\n",
    "    norm_mask = np.logical_and(rest_wavelength>=2000, rest_wavelength<=2500)\n",
    "    flux /= np.median(flux[norm_mask])\n",
    "\n",
    "    spectra.append(flux)\n",
    "    file_names.append(file_name)\n",
    "    zs.append(z)\n",
    "\n",
    "spectra = np.array(spectra)\n",
    "zs = np.array(zs)\n",
    "\n",
    "# Reshape spectra data to match the expected input shape\n",
    "spectra = np.expand_dims(spectra, axis=-1)\n",
    "\n",
    "X_train_spectra, X_val_spectra, X_train_zs, X_val_zs = train_test_split(spectra, zs, test_size=0.2, random_state=42)\n",
    "X_train = [X_train_spectra, X_train_zs]\n",
    "X_val = [X_val_spectra, X_val_zs]\n",
    "\n",
    "print(np.min(x), np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling ResampleLayer.call().\n\n\u001b[1mCannot convert '4500' to a shape.\u001b[0m\n\nArguments received by ResampleLayer.call():\n  • args=(['<KerasTensor shape=(None, 6989, 1), dtype=float32, sparse=False, name=keras_tensor_59>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_51>'],)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmin_observed_wavelength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_observed_wavelength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[4], line 168\u001b[0m, in \u001b[0;36mbuild_autoencoder\u001b[0;34m(input_shape, latent_dim, z_min, z_max, min_observed_wavelength, max_observed_wavelength)\u001b[0m\n\u001b[1;32m    165\u001b[0m encoder \u001b[38;5;241m=\u001b[39m build_encoder(input_shape, latent_dim)\n\u001b[1;32m    166\u001b[0m latent_space \u001b[38;5;241m=\u001b[39m encoder(spectra_input)\n\u001b[0;32m--> 168\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_observed_wavelength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_observed_wavelength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m reconstructed_output \u001b[38;5;241m=\u001b[39m decoder([latent_space, redshift_input])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(inputs\u001b[38;5;241m=\u001b[39m[spectra_input, redshift_input], outputs\u001b[38;5;241m=\u001b[39mreconstructed_output, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoencoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 157\u001b[0m, in \u001b[0;36mbuild_decoder\u001b[0;34m(latent_dim, output_dim, z_min, z_max, min_observed_wavelength, max_observed_wavelength)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(interpolated, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Specify output_shape\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mResampleLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrest_frame_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_observed_wavelength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_observed_wavelength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredshift_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model([latent_input, redshift_input], output, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/agn310b/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/agn310b/lib/python3.10/site-packages/optree/ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling ResampleLayer.call().\n\n\u001b[1mCannot convert '4500' to a shape.\u001b[0m\n\nArguments received by ResampleLayer.call():\n  • args=(['<KerasTensor shape=(None, 6989, 1), dtype=float32, sparse=False, name=keras_tensor_59>', '<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_51>'],)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "autoencoder = build_autoencoder(input_shape=(len(x), 1), latent_dim=10, z_min=1.5, z_max=2.2,\n",
    "                                min_observed_wavelength=np.min(x),\n",
    "                                max_observed_wavelength=np.max(x))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(X_train, X_train_spectra, epochs=1, batch_size=4, validation_data=(X_val, X_val_spectra))\n",
    "\n",
    "# Save the training history\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'])\n",
    "plt.plot(history_dict['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agn310b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
