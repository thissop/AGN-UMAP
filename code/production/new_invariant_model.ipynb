{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, PReLU, Input, Reshape, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def build_encoder(input_shape, latent_dim):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional Layers\n",
    "    x = Conv1D(filters=128, kernel_size=5, padding='valid', name='conv1')(input_layer)\n",
    "    x = PReLU(name='prelu1')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool1')(x)\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=11, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(name='prelu2')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool2')(x)\n",
    "\n",
    "    x = Conv1D(filters=512, kernel_size=21, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(name='prelu3')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='maxpool3')(x)\n",
    "\n",
    "    # Flatten the output from Conv layers\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    x = Dense(256, name='dense1')(x)\n",
    "    x = PReLU(name='prelu4')(x)\n",
    "    x = Dense(128, name='dense2')(x)\n",
    "    x = PReLU(name='prelu5')(x)\n",
    "    x = Dense(64, name='dense3')(x)\n",
    "    x = PReLU(name='prelu6')(x)\n",
    "\n",
    "    # Latent Space\n",
    "    latent_space = Dense(latent_dim, name='latent_space')(x)\n",
    "\n",
    "    return Model(input_layer, latent_space, name='encoder')\n",
    "\n",
    "def build_decoder(latent_dim, output_dim, min_rest_x, max_rest_x, observed_resolution, upsample_factor):\n",
    "    # Inputs: latent vector and scalar z\n",
    "    latent_input = Input(shape=(latent_dim,), name='latent_input')\n",
    "    z = Input(shape=(1,), name='z')  # Scalar input for z\n",
    "    \n",
    "    # Step 1: Fully Connected Layers to generate rest frame representation\n",
    "    x = Dense(64)(latent_input)\n",
    "    x = PReLU()(x)    \n",
    "    x = Dense(256)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    # Generate rest frame grid\n",
    "    rest_length = tf.cast((max_rest_x - min_rest_x) / observed_resolution * upsample_factor, tf.int32)\n",
    "    rest_x = tf.linspace(min_rest_x, max_rest_x, rest_length)\n",
    "\n",
    "    start_index = tf.cast(tf.argmin(tf.abs(rest_x - min_rest_x/(1+z)), axis=0), tf.int32)\n",
    "    stop_index = tf.cast(tf.argmin(tf.abs(rest_x - max_rest_x/(1+z)), axis=0), tf.int32)\n",
    "\n",
    "    x = Dense(rest_length)(x)\n",
    "    x = PReLU(x)\n",
    "\n",
    "    # Step 2: Downsample the tensor\n",
    "    \n",
    "    # Option 1: Select every second element (simple downsampling)\n",
    "    sliced_x = tf.slice(x, [start_index], [stop_index - start_index])\n",
    "    output = sliced_x[::upsample_factor]\n",
    "\n",
    "    # Option 2: Apply average pooling (another way of downsampling)\n",
    "   \n",
    "    output = Reshape((output_dim, 1))(output)\n",
    "\n",
    "    return Model(latent_input, output, name='decoder')\n",
    "\n",
    "def build_autoencoder(input_shape, latent_dim, min_rest_x, max_rest_x, observed_resolution, upsample_factor):\n",
    "    spectra_input = Input(shape=input_shape, name='spectra_input')\n",
    "    \n",
    "    # Building the encoder (you would define build_encoder separately)\n",
    "    encoder = build_encoder(input_shape, latent_dim)\n",
    "    latent_space = encoder(spectra_input)\n",
    "    \n",
    "    # Scalar z input for each iteration\n",
    "    z_input = Input(shape=(1,), name='z_input')\n",
    "    \n",
    "    # Building the decoder, which now takes both latent vector and scalar z\n",
    "\n",
    "    decoder = build_decoder(latent_dim, input_shape[0], min_rest_x, max_rest_x, observed_resolution, upsample_factor)\n",
    "    reconstructed_output = decoder([latent_space, z_input])\n",
    "\n",
    "    # Define the complete autoencoder model\n",
    "    return Model(inputs=[spectra_input, z_input], outputs=reconstructed_output, name='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m max_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.2\u001b[39m\n\u001b[1;32m      5\u001b[0m min_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[0;32m----> 7\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_rest_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_observed_x\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmax_z\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rest_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_observed_x\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmin_z\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved_resolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsample_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[3], line 91\u001b[0m, in \u001b[0;36mbuild_autoencoder\u001b[0;34m(input_shape, latent_dim, min_rest_x, max_rest_x, observed_resolution, upsample_factor)\u001b[0m\n\u001b[1;32m     87\u001b[0m z_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Building the decoder, which now takes both latent vector and scalar z\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_rest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_resolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsample_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m reconstructed_output \u001b[38;5;241m=\u001b[39m decoder([latent_space, z_input])\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Define the complete autoencoder model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m, in \u001b[0;36mbuild_decoder\u001b[0;34m(latent_dim, output_dim, min_rest_x, max_rest_x, observed_resolution, upsample_factor)\u001b[0m\n\u001b[1;32m     58\u001b[0m rest_length \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast((max_rest_x \u001b[38;5;241m-\u001b[39m min_rest_x) \u001b[38;5;241m/\u001b[39m observed_resolution \u001b[38;5;241m*\u001b[39m upsample_factor, tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     59\u001b[0m rest_x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinspace(min_rest_x, max_rest_x, rest_length)\n\u001b[0;32m---> 61\u001b[0m start_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39margmin(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrest_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_rest_x\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     62\u001b[0m stop_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39margmin(tf\u001b[38;5;241m.\u001b[39mabs(rest_x \u001b[38;5;241m-\u001b[39m max_rest_x\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mz)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(rest_length)(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/agn310b/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/agn310b/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/agn310b/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "max_observed_x = 10400\n",
    "min_observed_x = 3550\n",
    "observed_resolution = (max_observed_x-min_observed_x)/1500\n",
    "max_z = 2.2\n",
    "min_z = 1.5\n",
    "\n",
    "autoencoder = build_autoencoder(input_shape=(1500, 1), latent_dim=10, min_rest_x=min_observed_x/(1+max_z), max_rest_x=max_observed_x/(1+min_z), observed_resolution=observed_resolution, upsample_factor=2)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agn310b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
